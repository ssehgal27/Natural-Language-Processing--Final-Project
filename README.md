# AI-Generated Text Detection using Classic ML and PEFT/LoRA Transformers

This project aims to build an effective text classification system to distinguish between **AI-generated** and **human-written** text. It compares the performance of traditional machine learning models (Logistic Regression, Naive Bayes, SVM) with a fine-tuned **DistilBERT** model using **PEFT (LoRA)** to reduce training costs while maintaining high accuracy.

---

## Dataset

**Source:** [Kaggle - AI vs. Human Text](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text)  
The dataset consists of labeled text samples — either generated by LLMs like GPT or written by humans — for binary classification.

---

##  Project Highlights

-  Text Preprocessing (lowercasing, punctuation removal, etc.)
-  TF-IDF Vectorization for classic models
-  Logistic Regression, Naive Bayes, and SVM comparison
-  Fine-tuning DistilBERT with PEFT/LoRA (Parameter-Efficient Fine-Tuning)
-  Detailed Error & Confidence Analysis
-  Performance Evaluation using Accuracy, F1, Precision, and Recall


##  Model Performance

| Metric      | Best Classic Model (SVM) | PEFT/LoRA Fine-Tuned DistilBERT |
|-------------|---------------------------|----------------------------------|
| Accuracy    | 0.6288                    | 0.9476                           |
| F1 Score    | 0.4867                    | 0.9476                           |




## ▶️ Run the Notebook

 Open on Google Colab:  
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1r0fr4Re5NEKnfzoYZr9L9LYCnkZUPKCI?usp=sharing)

Make sure to:

- Enable GPU in Colab
- Upload or mount the Kaggle dataset before running

## Link to Google Drive for Presentation- https://drive.google.com/drive/folders/1ztTdcPhvHNn_h8SItChB4ArCoLlkxmIx?usp=share_link
---
